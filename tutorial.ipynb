{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4cfd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import darklight\n",
    "import tangos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e08f03",
   "metadata": {},
   "source": [
    "Import the simulation you'd like to run DarkLight on.  The following assumes that the database `Halo600.db` is in your current working directory.\n",
    "\n",
    "If analzying EDGE halos, see `tutorial-edge.ipynb` for notes on additional support in DarkLight for retrieving EDGE data on DiRAC or the Surrey servers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f543779",
   "metadata": {},
   "outputs": [],
   "source": [
    "tangos.core.init_db('Halo600.db')\n",
    "sim = tangos.get_simulation('Halo600_DMO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11714e1",
   "metadata": {},
   "source": [
    "This simulation contains lots of dark matter halos, but one giant 'main' halo.  The rest of the halos are much smaller. The simulations are run for the age of the universe, ~13.8 Gyr, and saves a bunch of 'snapshots' of the halo as it evolves over time. \n",
    "\n",
    "What we do here is get the last snapshot (timesteps[-1]), which corresponds to the present day (i.e. a redshift z = 0), and get the most massive halo (halos[0]), which will always be the first halo in the list of all halos, which is ordered by mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc724e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "halo = sim.timesteps[-1].halos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bceb24",
   "metadata": {},
   "source": [
    "Now that we have the halo, we can run DarkLight on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ff974",
   "metadata": {},
   "outputs": [],
   "source": [
    "t,z,vsmooth,sfh_insitu,mstar_insitu,mstar_total = darklight.DarkLight(halo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6eb3c8",
   "metadata": {},
   "source": [
    "The outputs are:\n",
    "\n",
    " - `t` = times [Gyr]\n",
    " - `z` = redshifts [unitless]\n",
    " - `vsmooth` = vmax over time, smoothed from simulation and suppressed to mimic lower vmaxes in hydro sims [km/s]\n",
    " - `sfh_insitu` = the star formation history of the galaxy that forms in this halo [Msun/yr]\n",
    " - `mstar_insitu` = integral of the (cumulative) in-situ star formation history [Msun]\n",
    " - `mstar_total` = total mass formed insitu + was accreted as little halos merged with this halo\n",
    "\n",
    "All of these output arrays are of the same length.\n",
    "\n",
    "Let's take a look at the star formation history and M* generated by DarkLight for this halo, and compare it against results from the full hydrodynamical simulations.  To do this comparison, we first have to get the halo from the corresponding hydro sim first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71230aa0-c71b-4fdc-9b1b-6638519c1de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = darklight.edge.load_tangos_data('Halo600_fiducial')\n",
    "hydro_halo = sim.timesteps[-1].halos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a8111-5532-42d0-98bb-58f0867a92d1",
   "metadata": {},
   "source": [
    "I've created a built-in function that plots DarkLight results against those from the full hydro sims.  For EDGE, the stellar masses calculated by DarkLight usually match the values from hydro simulations to within a factor of two or so, but won't be an exact match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf344f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "darklight.edge.plot_darklight_vs_edge_mstar(hydro_halo,t,z,vsmooth,sfh_insitu,mstar_total,mstar_insitu=mstar_insitu,figfn='halo'+shortname+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e03605f-84f0-4706-b7b6-cf958eb293e8",
   "metadata": {},
   "source": [
    "You can ask DarkLight to produce multiple realizations.  Generally, you'll find that if averaging multiple realizations will better match the EDGE simulations than if you created a single realization.  Here's an example running DarkLight with multiple realizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5508494e-71a5-4b1d-aac4-917850bb7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t,z,vsmooth,sfh_insitu,mstar_insitu,mstar_total = darklight.DarkLight(halo, n=100)\n",
    "darklight.edge.plot_darklight_vs_edge_mstar(hydro_halo,t,z,vsmooth,sfh_insitu,mstar_total,mstar_insitu=mstar_insitu,figfn='halo'+shortname+'-scatter.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad2d09",
   "metadata": {},
   "source": [
    "In the above examples, I've run it with the default DarkLight settings, but you can play with these settings by supplying some keyword arguments. The arguments that modify the input parameters that control DarkLight's behavior and their default values are:\n",
    "  \n",
    " - `vthres = 'falling'`, can also be a float [km/s]; the minimum vmax (the maximum velocity in the rotation curve) the halo must have to start forming stars again after reionization, given by a fit to the EDGE sims in Kim et al. 2024.\n",
    " - `zq = 4`, the redshift at which reionization quenching shuts star formation off\n",
    " - `occupation = 2.5e7` [msun] the occupation fraction (i.e. what halos have galaxies) to assume.  By default, assumes all halos with a mass above the given value (in solar masses) have galaxies.  The value used here reflects the mass down to which EDGE is resolved.  However, you can also ask DarkLight to assume all halos have galaxies (`'all'`), or use the occupation function from the EDGE1 sims (`'edge1'`), the EDGE1 RT sims (`'edge1rt'`), or a fit to observed Milky Way dwarfs (`'nadler20'`).\n",
    " - `prequench = 'fiducial'`, the SFR-vmax relation to use before reionization quenching\n",
    " - `postquench = 'schechter'`, the SFR-vmax relation to use after reionization quenching\n",
    " - `postquench_scatter='increasing'`, what scatter to assume for the SFR-vmax relation after reionization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c9087-f487-4d85-b53c-fc052eb5a961",
   "metadata": {},
   "source": [
    "There's also a few other parameters that you can modify:\n",
    "\n",
    " - `mapping = 3bins`, controls how to map the SFR-vmax relations into SFHs.  `3bins` assigns a single SFR before reionization quenching based on the average vmax in that period (bin 1), zero after reionization when the halo's vmax < vthres (bin 2), and a single SFR if vmax > vthres based on its vmax at z=0 (bin 3).  You can also specify `'all'` to have it update the SFR based on the vmax at each timestep. \n",
    " - `timesteps = sim` [Gyr], the time resolution to produce the SFH and thus M*(t), which by default will use the timesteps in the simulation.  You can instead also specify a timestep in units of Gyr.\n",
    " - `mergers = True`, whether or not to include the contribution to M* from in-situ star formation, mergers, or both.  `True` includes both, `False` only the in-situ stars, and `'only'` only the accreted stars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
